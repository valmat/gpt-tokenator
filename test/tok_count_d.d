#!/usr/bin/rdmd --shebang= -I. -L../libs/libtokenator.a -L-licuuc -L-licui18n -L-lm -L-lstdc++ -w -debug 

import std.stdio;
import std.string;
import std.array;
import std.typecons;

extern (C)
size_t tokenator_count(const char* data, size_t len) pure nothrow;

int main() {

    auto phrases = [
        tuple(4   , "Ddfgdgd"),
        tuple(4   , "dfgdfg"),
        tuple(11  , "df  f dfg dr  rg  d "),
        tuple(2   , "  "),
        tuple(1   , " "),
        tuple(1   , "_"),
        tuple(0   , ""),
        tuple(1   , "_______"),
        tuple(10  , "This is a test, and it's working!"),
        tuple(24  , "This is an example sentence to try encoding out on! &#8211; ĞŸÑ€Ğ¸Ğ²ĞµÑ‚!"),
        tuple(156 , "Ğ¡Ğ¾ĞµĞ´Ğ¸Ğ½Ğ¸Ğ² Ğ´Ğ²Ğ° ÑĞ»Ğ¾Ğ²Ğ° Ğ¼Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Â«Ğ³Ğ°Ğ¼Ğ°Ñ€Ğ´Ğ¶Ğ¾Ğ±Ğ° Ğ³ĞµĞ½Ğ°Ñ†Ğ²Ğ°Ğ»ĞµÂ» áƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ, Ñ‡Ñ‚Ğ¾ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ²ÑƒÑ‡Ğ°Ñ‚ÑŒ ĞºĞ°Ğº Â«Ğ·Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹, Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğ¹ Ğ´Ñ€ÑƒĞ³Â»"),
        tuple(1   , "This"),
        tuple(27  , "áƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ"),
        tuple(55  , `{"title": string,"totalResults": string,"searchTerms": string,"count": integer,"startIndex": integer,"startPage": integer,"language": string,"inputEncoding": string,"outputEncoding": string,"safe": string,"cx": string}`),
        tuple(58  , "ğŸ˜¢ğŸ˜ŸğŸ¤“ğŸ˜ğŸ˜­ğŸ˜¶â€ğŸŒ«ï¸ğŸ¥µğŸ˜¦ğŸ¥¶ğŸ˜³âœ…â¤ï¸ğŸ˜³ğŸ¤ğŸ˜©ğŸ˜ğŸ˜¢âŒğŸŒ·â•ğŸ‡ºğŸ‡¦"),
        tuple(299 , "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑ! (Ñ€ÑƒÑÑĞºĞ¸Ğ¹); Hello! (Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹); Bonjour! (Ñ„Ñ€Ğ°Ğ½Ñ†ÑƒĞ·ÑĞºĞ¸Ğ¹); Hola! (Ğ¸ÑĞ¿Ğ°Ğ½ÑĞºĞ¸Ğ¹); Hallo! (Ğ½ĞµĞ¼ĞµÑ†ĞºĞ¸Ğ¹); Ciao! (Ğ¸Ñ‚Ğ°Ğ»ÑŒÑĞ½ÑĞºĞ¸Ğ¹); OlÃ¡! (Ğ¿Ğ¾Ñ€Ñ‚ÑƒĞ³Ğ°Ğ»ÑŒÑĞºĞ¸Ğ¹); ã“ã‚“ã«ã¡ã¯ï¼(ÑĞ¿Ğ¾Ğ½ÑĞºĞ¸Ğ¹); ì•ˆë…•í•˜ì„¸ìš”! (ĞºĞ¾Ñ€ĞµĞ¹ÑĞºĞ¸Ğ¹); ä½ å¥½ï¼(ĞºĞ¸Ñ‚Ğ°Ğ¹ÑĞºĞ¸Ğ¹); Ğ¿Ñ€Ñ‹Ğ²Ñ–Ñ‚Ğ°Ğ½Ğ½Ğµ! (Ğ±ĞµĞ»Ğ¾Ñ€ÑƒÑÑĞºĞ¸Ğ¹); Ğ—Ğ´Ñ€Ğ°Ğ²Ğ¾! (ÑĞµÑ€Ğ±ÑĞºĞ¸Ğ¹); Ğ—Ğ´Ñ€Ğ°Ğ²Ğ¾! (Ğ¼Ğ°ĞºĞµĞ´Ğ¾Ğ½ÑĞºĞ¸Ğ¹); Ğ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹Ñ‚Ğµ! (Ğ±Ğ¾Ğ»Ğ³Ğ°Ñ€ÑĞºĞ¸Ğ¹)"),
        tuple(197 , "Hello! Ğ’Ñ–Ñ‚Ğ°Ñ! Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ! Bonjour! Â¡Hola! Ciao! OlÃ¡! ã“ã‚“ã«ã¡ã¯ï¼(Konnichiwa!) ì•ˆë…•í•˜ì„¸ìš”! (Annyeonghaseyo!) ä½ å¥½ï¼(NÇ hÇo!) áƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ! (Gamardjoba!) Ô²Õ¡Ö€Ö‡ ÕÕ¥Õ¦! (Barev Dzez!) Î“ÎµÎ¹Î± ÏƒÎ±Ï‚! (Geia sas!) Merhaba! Ğ˜ÑÓ™Ğ½Ğ¼ĞµÑĞµĞ·! (IsÃ¤nmesez!)"),
    ];

    foreach (phrase; phrases) {
        size_t count = tokenator_count(phrase[1].ptr, phrase[1].length);
        writeln("phrase (", count, " ):\t", phrase[1]);
        assert(count == phrase[0]);
    }

    return 0;
}